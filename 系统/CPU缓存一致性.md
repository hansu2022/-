还有写操作，那么如果数据写入 Cache 之后，内存与 Cache 相对应的数据将会不同，这种情况下 Cache 和内存数据都不一致了，于是我们肯定是要把 Cache 中的数据同步到内存里的。
问题来了，那在什么时机才把 Cache 中的数据写回到内存呢？为了应对这个问题，下面介绍两种针对写入数据的方法：

- 写直达（_Write Through_）
- 写回（_Write Back_）
### [#](https://xiaolincoding.com/os/1_hardware/cpu_mesi.html#%E5%86%99%E7%9B%B4%E8%BE%BE)写直达

保持内存与 Cache 一致性最简单的方式是，**把数据同时写入内存和 Cache 中**，这种方法称为**写直达（_Write Through_）**。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/%E5%86%99%E7%9B%B4%E8%BE%BE.png)

在这个方法里，写入前会先判断数据是否已经在 CPU Cache 里面了：

- 如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；
- 如果数据没有在 Cache 里面，就直接把数据更新到内存里面。

写直达法很直观，也很简单，但是问题明显，无论数据在不在 Cache 里面，每次写操作都会写回到内存，这样写操作将会花费大量的时间，无疑性能会受到很大的影响。

### [#](https://xiaolincoding.com/os/1_hardware/cpu_mesi.html#%E5%86%99%E5%9B%9E)写回

既然写直达由于每次写操作都会把数据写回到内存，而导致影响性能，于是为了要减少数据写回内存的频率，就出现了**写回（_Write Back_）的方法**。
写回（Write Back）机制的核心理念就一个字：**懒**。
**写回**的做法是：**只把数据更新到离CPU最近、速度最快的Cache中，然后给这个数据块贴一个“脏”（Dirty）标签**，表示“我这里的数据跟主内存不一样了，我已经修改过了”。

在写回机制中，**当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中**，减少了数据写回内存的频率，这样便可以提高系统的性能。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/%E5%86%99%E5%9B%9E1.png)

那具体如何做到的呢？下面来详细说一下：

#### **1. 命中缓存（Cache Hit）**
这是最理想的情况。当CPU要写一个数据时，发现这个数据已经在Cache里了。
- **处理过程**：
    - CPU直接在Cache里更新这个数据。
    - 给这个数据块贴上“脏”（Dirty）标签。
    - **结束**！不需要理会主内存。
- **为什么要这么做？**
    - 因为主内存很慢，而Cache很快。如果每次都同步到主内存，那处理器的速度优势就没了。
    - 通过这个“脏”标签，处理器告诉系统：“我稍后会处理这个数据，现在先别动它。”
#### **2. 未命中缓存（Cache Miss）**
当CPU要写一个数据时，发现这个数据不在Cache里。这时候，为了给新数据腾地方，系统必须把Cache里的一个旧数据块“**替换**”出去。
这个“替换”的过程就是写回机制最关键的一步。
- **处理过程**：
    - 首先，系统会检查即将被“替换”的旧数据块。
    - **如果旧数据块是“脏”的**：
        - 这意味着这个旧数据块在Cache里被修改过，但还没同步回主内存。
        - 为了不丢失数据，系统**必须先**把这个旧数据块的内容**写回主内存**。
        - 然后，把新数据从主内存读入到这个位置。
        - 最后，在新数据写入后，给这个数据块也打上“脏”标签。
            
    - **如果旧数据块不是“脏”的**：
        - 这意味着旧数据块的内容和主内存是一致的，没有被修改过。
        - 直接把新数据从主内存读入，覆盖掉旧数据即可。
        - 给新数据块打上“脏”标签。
- **为什么要这么做？**
    - **为了保证数据完整性**。如果一个被修改过的数据块（脏数据）在没有写回主内存的情况下就被替换掉了，那么数据就永远丢失了。
    - **为了提高效率**。当一个脏数据被多次修改，只要它还在Cache里，就只用在Cache里更新就行了，只有在它要被替换出去时，才一次性写回主内存。这大大减少了对慢速内存的写操作。

### **先读入再写入？**
核心原因在于 **CPU和内存的最小传输单位不同**。
- **CPU读写单位**：CPU通常以字节（byte）、字（word，4字节）等较小的单位进行读写操作。
- **缓存和内存的传输单位**：缓存（Cache）和主内存（Main Memory）之间的数据传输，通常是以一个**数据块**（Cache Block）为单位。一个数据块可能包含多个字，比如 32 字节或 64 字节。
假设：
- **缓存块**的大小为 32 字节。
- CPU 要写入一个 **4 字节**的数据。
- 这个 4 字节的数据，目前不在缓存里。

现在我们来详细看这个过程，分步拆解：
1. **CPU 请求写入**：CPU 想要把一个 4 字节的新数据写入到内存地址 `A`。
2. **缓存检查**：缓存控制器发现地址 `A` 对应的**整个 32 字节数据块**并不在缓存中，这就是“未命中”。
3. **从内存读取**：为了给 CPU 的写入操作提供完整的上下文，缓存控制器必须先从主内存中，将地址 `A` 所在的那个**完整的 32 字节数据块**读取出来。这 32 个字节包含了 CPU 要写入的那个 4 字节，以及它旁边的 28 个字节。
4. **载入缓存**：这个从内存中读取的 32 字节数据块被载入到缓存中，覆盖掉原来的旧数据块。
5. **CPU 写入**：现在，CPU 可以在缓存里找到这个完整的 32 字节数据块了。它会找到其中对应的 4 字节位置，然后把自己的新数据**覆盖**写入到这 4 个字节上。
6. **标记为“脏”**：这个被部分修改过的 32 字节数据块被标记为“脏”。
![[Pasted image 20250923122305.png]]
CPU 缓存与内存使用「写回」机制的流程图如下，左半部分就是读操作的流程，右半部分就是写操作的流程，也就是我们上面讲的内容。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/writeback.png)
## [#](https://xiaolincoding.com/os/1_hardware/cpu_mesi.html#%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98)## 缓存一致性问题

在现代多核 CPU 系统中，每个核心通常都有自己独立的 **L1 和 L2 缓存**。当多个核心同时操作同一个共享变量时，就会产生“缓存一致性”问题。

如果不能保证缓存数据的一致性，不同的核心可能会读取到旧的、错误的数据，从而导致程序执行结果出错。

假设 A 号核心和 B 号核心同时运行两个线程，都操作共同的变量 i（初始值为 0 ）。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E4%BE%8B%E5%AD%90.png)

- **步骤 1 (核心 A 修改)**：核心 A 执行 `i++`。为了提高性能，它采用**写回（Write Back）**策略，将 `i` 的新值 `1` 写入自己的 L1/L2 缓存中，并标记为“脏（Dirty）”。此时，主内存中的 `i` 值仍然是 `0`。
- **步骤 2 (核心 B 读取)**：如果此时核心 B 尝试从主内存中读取 `i` 的值，它读到的会是旧的、错误的值 `0`，而不是核心 A 缓存里的新值 `1`。
这就是缓存一致性问题：核心 A 的缓存和核心 B 的缓存，以及主内存之间的数据**不一致**。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E4%BE%8B%E5%AD%902.png)

那么，要解决这一问题，就需要一种机制，来同步两个不同核心里面的缓存数据。要实现的这个机制的话，要保证做到下面这 2 点：

- 第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为**写传播（_Write Propagation_）**；
- 第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为**事务的串行化（_Transaction Serialization_）**。

第一点写传播很容易就理解，当某个核心在 Cache 更新了数据，就需要同步到其他核心的 Cache 里。而对于第二点事务的串行化，我们举个例子来理解它。

假设我们有一个含有 4 个核心的 CPU，这 4 个核心都操作共同的变量 i（初始值为 0 ）。A 号核心先把 i 值变为 100，而此时同一时间，B 号核心先把 i 值变为 200，这里两个修改，都会「传播」到 C 和 D 号核心。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/%E4%BA%8B%E4%BB%B6%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%98.png)

那么问题就来了，C 号核心先收到了 A 号核心更新数据的事件，再收到 B 号核心更新数据的事件，因此 C 号核心看到的变量 i 是先变成 100，后变成 200。

而如果 D 号核心收到的事件是反过来的，则 D 号核心看到的是变量 i 先变成 200，再变成 100，虽然是做到了写传播，但是各个 Cache 里面的数据还是不一致的。

所以，我们要保证 C 号核心和 D 号核心都能看到**相同顺序的数据变化**，比如变量 i 都是先变成 100，再变成 200，这样的过程就是事务的串行化。

要实现事务串行化，要做到 2 点：

- CPU 核心对于 Cache 中数据的操作，需要同步给其他 CPU 核心；
- 要引入「锁」的概念，如果两个 CPU 核心里有相同数据的 Cache，那么对于这个 Cache 数据的更新，只有拿到了「锁」，才能进行对应的数据更新。

那接下来我们看看，写传播和事务串行化具体是用什么技术实现的。

---
1. **写传播（Write Propagation）**
    - **定义**：当某个 CPU 核心的缓存数据被更新时，必须将这个更新传播到其他所有核心的缓存中。
    - **作用**：确保一个核心的修改能被其他核心“看见”，避免其他核心读取到旧数据。
2. **事务的串行化（Transaction Serialization）**
    - **定义**：所有核心对同一数据的操作顺序，在所有核心看来都必须是一样的。
    - **作用**：解决多个核心同时修改一个变量的冲突问题，确保最终结果的确定性。
    - **举例**：假设有 4 个核心（A、B、C、D）同时操作变量 `i`。核心 A 试图将 `i` 修改为 `100`，同时核心 B 试图将 `i` 修改为 `200`。虽然这两个修改都会传播到其他核心，但必须有一个**确定的顺序**，例如先是 `100`，后是 `200`，这样 C 和 D 核心才能确定地看到最终结果是 `200`，而不是一个不确定的值。
## [#](https://xiaolincoding.com/os/1_hardware/cpu_mesi.html#%E6%80%BB%E7%BA%BF%E5%97%85%E6%8E%A2)总线嗅探
**总线嗅探**是一种实现**写传播**（Write Propagation）的常见机制，它解决了多核 CPU 缓存一致性问题中的第一个难题。
- **工作原理**：当一个 CPU 核心（例如核心 A）更新了自己缓存中的数据时，它会通过**总线（Bus）**向所有其他核心广播一个通知。每个核心都会持续**监听**总线上的活动。
- **数据同步**：如果一个核心（例如核心 B）监听到这个广播，并发现自己缓存中也有一份相同的数据副本，它就会将自己的数据同步（例如，使之失效）。
- **局限性**：
    - **总线负载**：不管其他核心是否缓存了相同的数据，每次更新都需要发送广播，这会显著增加总线的负载。
    - **无法保证事务串行化**：总线嗅探只能保证数据更新的通知被发送，但无法确保多个核心同时进行修改时的操作顺序是统一的。

## [#](https://xiaolincoding.com/os/1_hardware/cpu_mesi.html#mesi-%E5%8D%8F%E8%AE%AE)## MESI 协议

MESI 协议其实是 4 个状态单词的开头字母缩写，分别是：

- _Modified_，已修改
- _Exclusive_，独占
- _Shared_，共享
- _Invalidated_，已失效

这四个状态来标记 Cache Line 四个不同的状态。

「已修改」状态就是我们前面提到的脏标记，代表该 Cache Block 上的数据已经被更新过，但是还没有写到内存里。而「已失效」状态，表示的是这个 Cache Block 里的数据已经失效了，不可以读取该状态的数据。

「独占」和「共享」状态都代表 Cache Block 里的数据是干净的，也就是说，这个时候 Cache Block 里的数据和内存里面的数据是一致性的。

「独占」和「共享」的差别在于，独占状态的时候，数据只存储在一个 CPU 核心的 Cache 里，而其他 CPU 核心的 Cache 没有该数据。这个时候，如果要向独占的 Cache 写数据，就可以直接自由地写入，而不需要通知其他 CPU 核心，因为只有你这有这个数据，就不存在缓存一致性的问题了，于是就可以随便操作该数据。

另外，在「独占」状态下的数据，如果有其他核心从内存读取了相同的数据到各自的 Cache ，那么这个时候，独占状态下的数据就会变成共享状态。

那么，「共享」状态代表着相同的数据在多个 CPU 核心的 Cache 里都有，所以当我们要更新 Cache 里面的数据的时候，不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后再更新当前 Cache 里面的数据。

我们举个具体的例子来看看这四个状态的转换：

1. 当 A 号 CPU 核心从内存读取变量 i 的值，数据被缓存在 A 号 CPU 核心自己的 Cache 里面，此时其他 CPU 核心的 Cache 没有缓存该数据，于是标记 Cache Line 状态为「独占」，此时其 Cache 中的数据与内存是一致的；
2. 然后 B 号 CPU 核心也从内存读取了变量 i 的值，此时会发送消息给其他 CPU 核心，由于 A 号 CPU 核心已经缓存了该数据，所以会把数据返回给 B 号 CPU 核心。在这个时候， A 和 B 核心缓存了相同的数据，Cache Line 的状态就会变成「共享」，并且其 Cache 中的数据与内存也是一致的；
3. 当 A 号 CPU 核心要修改 Cache 中 i 变量的值，发现数据对应的 Cache Line 的状态是共享状态，则要向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后 A 号 CPU 核心才更新 Cache 里面的数据，同时标记 Cache Line 为「已修改」状态，此时 Cache 中的数据就与内存不一致了。
4. 如果 A 号 CPU 核心「继续」修改 Cache 中 i 变量的值，由于此时的 Cache Line 是「已修改」状态，因此不需要给其他 CPU 核心发送消息，直接更新数据即可。
5. 如果 A 号 CPU 核心的 Cache 里的 i 变量对应的 Cache Line 要被「替换」，发现 Cache Line 状态是「已修改」状态，就会在替换前先把数据同步到内存。

所以，可以发现当 Cache Line 状态是「已修改」或者「独占」状态时，修改更新其数据不需要发送广播给其他 CPU 核心，这在一定程度上减少了总线带宽压力。

事实上，整个 MESI 的状态可以用一个有限状态机来表示它的状态流转。还有一点，对于不同状态触发的事件操作，可能是来自本地 CPU 核心发出的广播事件，也可以是来自其他 CPU 核心通过总线发出的广播事件。下图即是 MESI 协议的状态图：

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/MESI%E5%8D%8F%E8%AE%AE.png)

MESI 协议的四种状态之间的流转过程，我汇总成了下面的表格，你可以更详细的看到每个状态转换的原因：

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/%20MESI%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2%E8%A1%A8%E6%A0%BC.png)

---

## [#](https://xiaolincoding.com/os/1_hardware/cpu_mesi.html#%E6%80%BB%E7%BB%93)总结

CPU 在读写数据的时候，都是在 CPU Cache 读写数据的，原因是 Cache 离 CPU 很近，读写性能相比内存高出很多。对于 Cache 里没有缓存 CPU 所需要读取的数据的这种情况，CPU 则会从内存读取数据，并将数据缓存到 Cache 里面，最后 CPU 再从 Cache 读取数据。

而对于数据的写入，CPU 都会先写入到 Cache 里面，然后再在找个合适的时机写入到内存，那就有「写直达」和「写回」这两种策略来保证 Cache 与内存的数据一致性：

- 写直达，只要有数据写入，都会直接把数据写入到内存里面，这种方式简单直观，但是性能就会受限于内存的访问速度；
- 写回，对于已经缓存在 Cache 的数据的写入，只需要更新其数据就可以，不用写入到内存，只有在需要把缓存里面的脏数据交换出去的时候，才把数据同步到内存里，这种方式在缓存命中率高的情况，性能会更好；

当今 CPU 都是多核的，每个核心都有各自独立的 L1/L2 Cache，只有 L3 Cache 是多个核心之间共享的。所以，我们要确保多核缓存是一致性的，否则会出现错误的结果。

要想实现缓存一致性，关键是要满足 2 点：

- 第一点是写传播，也就是当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心；
- 第二点是事物的串行化，这个很重要，只有保证了这个，才能保障我们的数据是真正一致的，我们的程序在各个不同的核心上运行的结果也是一致的；

基于总线嗅探机制的 MESI 协议，就满足上面了这两点，因此它是保障缓存一致性的协议。

MESI 协议，是已修改、独占、共享、已失效这四个状态的英文缩写的组合。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心。

---

## [#](https://xiaolincoding.com/os/1_hardware/cpu_mesi.html#%E5%85%B3%E6%B3%A8%E4%BD%9C%E8%80%85)关注作者